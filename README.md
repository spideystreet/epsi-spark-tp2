# Projet de PrÃ©diction de SuccÃ¨s de Campagnes Kickstarter

Ce projet s'inscrit dans le cadre du TP nÂ°2 du module Spark. L'objectif est de construire un pipeline de prÃ©traitement (pre-processing) de donnÃ©es robustes avec Scala et Spark, afin de prÃ©parer un jeu de donnÃ©es pour l'entraÃ®nement d'un modÃ¨le de Machine Learning capable de prÃ©dire le succÃ¨s d'une campagne de financement participatif sur la plateforme Kickstarter.

---

## ğŸš€ Technologies utilisÃ©es

*   **Langage :** Scala (version 2.13.14)
*   **Framework de calcul distribuÃ© :** Apache Spark
*   **Outil de build :** sbt (Simple Build Tool)

---

## ğŸ“‚ Structure du projet

```
.
â”œâ”€â”€ build.sbt                 # Fichier de configuration pour sbt (dÃ©pendances, version de Scala...)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv             # DonnÃ©es brutes des campagnes Kickstarter.
â”‚   â””â”€â”€ kickstarter_preprocessed/ # Dossier de sortie contenant le DataFrame final au format Parquet.
â”œâ”€â”€ launchScalaApp.zsh        # Script shell pour compiler et lancer l'application.
â”œâ”€â”€ project/                  # Fichiers de configuration internes de sbt.
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ scala/
â”‚           â””â”€â”€ SimpleApp.scala # Le code source de l'application Spark.
â””â”€â”€ README.md                 # Ce fichier.
```

---

## ğŸ› ï¸ Comment lancer le pipeline

Le projet utilise `sbt` qui gÃ¨re Ã  la fois la compilation du code Scala et l'exÃ©cution de l'application Spark.

Pour lancer l'intÃ©gralitÃ© du pipeline de traitement :

1.  **Assurez-vous d'Ãªtre Ã  la racine du projet.**
2.  **Rendez le script de lancement exÃ©cutable (Ã  faire une seule fois) :**
    ```bash
    chmod +x launchScalaApp.zsh
    ```
3.  **ExÃ©cutez le script :**
    ```bash
    ./launchScalaApp.zsh
    ```

Le script va :
1.  Compiler le code source Scala.
2.  TÃ©lÃ©charger les dÃ©pendances nÃ©cessaires (Spark, etc.).
3.  Lancer l'application Spark.
4.  Effectuer toutes les Ã©tapes de nettoyage et de transformation.
5.  Sauvegarder le DataFrame final dans le dossier `data/kickstarter_preprocessed`.

---

## âœ¨ Ã‰tapes du pipeline de prÃ©traitement

Le script `SimpleApp.scala` effectue les opÃ©rations suivantes, conformÃ©ment au sujet du TP :

1.  **Chargement des DonnÃ©es :**
    *   Lecture du fichier `data/train.csv`.
    *   Utilisation de `try_cast` pour convertir les colonnes numÃ©riques (`goal`, `final_status`) et les timestamps (`deadline`, etc.) de maniÃ¨re sÃ©curisÃ©e, en ignorant les lignes mal formatÃ©es.

2.  **Nettoyage (Cleaning) :**
    *   Suppression des colonnes jugÃ©es inutiles ou prÃ©sentant des fuites du futur (`disable_communication`, `backers_count`, `state_changed_at`).
    *   CrÃ©ation et application d'UDFs (User Defined Functions) pour nettoyer et standardiser les colonnes `country` et `currency`.
    *   Filtrage du dataset pour ne conserver que les projets ayant un statut final clair (succÃ¨s `1` ou Ã©chec `0`).

3.  **IngÃ©nierie de fonctionnalitÃ©s (Feature Engineering) :**
    *   Calcul de la durÃ©e de la campagne en jours (`days_campaign`).
    *   Calcul du temps de prÃ©paration de la campagne en heures (`hours_prepa`).
    *   Mise en minuscule et concatÃ©nation des colonnes textuelles (`name`, `desc`, `keywords`) en une seule colonne `text`.

4.  **Finalisation et Sauvegarde :**
    *   Remplacement des valeurs `null` restantes par des valeurs par dÃ©faut.
    *   Sauvegarde du DataFrame final au format **Parquet** dans `data/kickstarter_preprocessed`, un format optimisÃ© pour les analyses Spark.